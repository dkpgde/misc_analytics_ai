{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Jo_CinzXi2_B",
        "outputId": "385da593-ee0b-4225-b191-c70696d1bbec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/SAP-samples/sap-rpt-1-oss\n",
            "  Cloning https://github.com/SAP-samples/sap-rpt-1-oss to /tmp/pip-req-build-2vxuo3az\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/SAP-samples/sap-rpt-1-oss /tmp/pip-req-build-2vxuo3az\n",
            "  Resolved https://github.com/SAP-samples/sap-rpt-1-oss to commit 4310453f3bbb9c9c403b029e966565e7fe652d97\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers>=4.52.4 in /usr/local/lib/python3.12/dist-packages (from sap_rpt_oss==1.0.1) (4.57.3)\n",
            "Collecting torcheval>=0.0.7 (from sap_rpt_oss==1.0.1)\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: torch>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from sap_rpt_oss==1.0.1) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from sap_rpt_oss==1.0.1) (1.6.1)\n",
            "Collecting pandas>=2.2.3 (from sap_rpt_oss==1.0.1)\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=20.0.0 (from sap_rpt_oss==1.0.1)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from sap_rpt_oss==1.0.1) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->sap_rpt_oss==1.0.1) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->sap_rpt_oss==1.0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->sap_rpt_oss==1.0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->sap_rpt_oss==1.0.1) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->sap_rpt_oss==1.0.1) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->sap_rpt_oss==1.0.1) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.1->sap_rpt_oss==1.0.1) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->sap_rpt_oss==1.0.1) (3.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.52.4->sap_rpt_oss==1.0.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.52.4->sap_rpt_oss==1.0.1) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.52.4->sap_rpt_oss==1.0.1) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.52.4->sap_rpt_oss==1.0.1) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.52.4->sap_rpt_oss==1.0.1) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.52.4->sap_rpt_oss==1.0.1) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.52.4->sap_rpt_oss==1.0.1) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->sap_rpt_oss==1.0.1) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->sap_rpt_oss==1.0.1) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.7.0->sap_rpt_oss==1.0.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.7.0->sap_rpt_oss==1.0.1) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.52.4->sap_rpt_oss==1.0.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.52.4->sap_rpt_oss==1.0.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.52.4->sap_rpt_oss==1.0.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.52.4->sap_rpt_oss==1.0.1) (2025.11.12)\n",
            "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m139.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sap_rpt_oss\n",
            "  Building wheel for sap_rpt_oss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sap_rpt_oss: filename=sap_rpt_oss-1.0.1-py3-none-any.whl size=29536 sha256=82c4a9c866aeca11042662cb45bccda97eec9c62e0dbe92a191154ca6f2eb977\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uygpbsdy/wheels/47/f7/8a/c7f6bf9317e95b984d3fb38049f3f0a63a376a83b72c98c5fc\n",
            "Successfully built sap_rpt_oss\n",
            "Installing collected packages: torcheval, pyarrow, pandas, sap_rpt_oss\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.3.3 pyarrow-22.0.0 sap_rpt_oss-1.0.1 torcheval-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/SAP-samples/sap-rpt-1-oss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zC1hWuSd0xB",
        "outputId": "a8321c27-923e-4a16-e89a-b73406a60022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.3.3)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.11.12)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XukIYm4Ri6PJ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sap_rpt_oss import SAP_RPT_OSS_Classifier, SAP_RPT_OSS_Regressor\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, r2_score, roc_auc_score\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.utils.multiclass import type_of_target\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from ucimlrepo import fetch_ucirepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63wL6SfOmEBV",
        "outputId": "b49906b9-b7c8-439d-a62c-6b367523090d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully logged in to Hugging Face!\n"
          ]
        }
      ],
      "source": [
        "HF_TOKEN=userdata.get('HF_TOKEN')\n",
        "if HF_TOKEN:\n",
        "    login(HF_TOKEN)\n",
        "    print(\"Successfully logged in to Hugging Face!\")\n",
        "else:\n",
        "    print(\"Token is not set. Please save the token first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3krUtZVVi6lL"
      },
      "outputs": [],
      "source": [
        "def load_and_split_data():\n",
        "    \"\"\"Load salary dataset\"\"\"\n",
        "    path = '...'\n",
        "    print(f\"Loading dataset from {path}...\")\n",
        "\n",
        "    # turns ? into nans and skips extra spaces\n",
        "    df = pd.read_csv(path, na_values=['?', ' ?'], skipinitialspace=True)\n",
        "\n",
        "    target_col = 'income' if 'income' in df.columns else df.columns[-1]\n",
        "\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y_series = df[target_col]\n",
        "\n",
        "    # convert targets for classification\n",
        "    y = y_series.astype(str).str.strip().apply(lambda x: 1 if '>50K' in x else 0)\n",
        "\n",
        "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "   # test values (for classification) not corrupted\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, categorical_cols, numerical_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUSh1c96dsLb"
      },
      "outputs": [],
      "source": [
        "def load_gas_turbine_data():\n",
        "    \"\"\"Load Gas Turbine dataset\"\"\"\n",
        "    print(\"Loading Gas Turbine dataset...\")\n",
        "\n",
        "    # fetching via ucimlrepo\n",
        "    dataset = fetch_ucirepo(id=551)\n",
        "    X = dataset.data.features\n",
        "    y = dataset.data.targets\n",
        "    df = pd.concat([X, y], axis=1)\n",
        "\n",
        "    print(f\"Data Loaded: {df.shape}\")\n",
        "\n",
        "    # Tregression task - emission preditction\n",
        "    target_col = 'CO'\n",
        "\n",
        "    # drop other target\n",
        "    if 'NOx' in df.columns:\n",
        "        df = df.drop(columns=['NOx'])\n",
        "\n",
        "    y = df[target_col]\n",
        "    X = df.drop(columns=[target_col])\n",
        "\n",
        "    numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "    categorical_cols = [] # none in this dataset, but needed for return consistency with the other function\n",
        "\n",
        "    # same split\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, categorical_cols, numerical_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdIs2lD6jCd0"
      },
      "outputs": [],
      "source": [
        "def corrupt_data(X, numerical_cols, mechanism='MCAR', ratio=0.3, min_prob=0.05):\n",
        "    \"\"\"\n",
        "    Corrupts data based on the specified mechanism.\n",
        "\n",
        "    Parameters:\n",
        "    - mechanism: 'MCAR' (uniform random) or 'MNAR' (U-shaped distribution).\n",
        "    - ratio: Missing rate for MCAR, or corruption strength for MNAR.\n",
        "    \"\"\"\n",
        "    X_corrupt = X.copy()\n",
        "\n",
        "    if mechanism == 'MCAR':\n",
        "        print(f\"  > Applying MCAR corruption (rate={ratio})...\")\n",
        "        for col in numerical_cols:\n",
        "            mask = np.random.rand(len(X_corrupt)) < ratio\n",
        "            X_corrupt.loc[mask, col] = np.nan\n",
        "\n",
        "    elif mechanism == 'MNAR':\n",
        "        print(f\"  > Applying MNAR corruption (strength={ratio})...\")\n",
        "        for col in numerical_cols:\n",
        "            # percentile ranking\n",
        "            p_rank = X_corrupt[col].rank(pct=True)\n",
        "\n",
        "            # distance from median. x2 to normalize distance [0, 1]\n",
        "            dist_from_median = 2 * np.abs(p_rank - 0.5)\n",
        "\n",
        "            # probability of deletion = Base + (Strength * Normalized_Distance)\n",
        "            prob_missing = min_prob + (ratio * dist_from_median)\n",
        "\n",
        "            # masking\n",
        "            mask = np.random.rand(len(X_corrupt)) < prob_missing\n",
        "            X_corrupt.loc[mask, col] = np.nan\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown mechanism: {mechanism}\")\n",
        "\n",
        "    return X_corrupt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOaWLUeGjDD4"
      },
      "outputs": [],
      "source": [
        "def impute_baseline(X_train, categorical_cols, numerical_cols):\n",
        "    \"\"\"Mean (Num) / Mode (Cat) Imputation\"\"\"\n",
        "    start = time.time()\n",
        "\n",
        "    X_filled = X_train.copy()\n",
        "\n",
        "    if numerical_cols:\n",
        "        num_imputer = SimpleImputer(strategy='mean')\n",
        "        X_filled[numerical_cols] = num_imputer.fit_transform(X_train[numerical_cols])\n",
        "\n",
        "    if categorical_cols:\n",
        "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "        X_filled[categorical_cols] = cat_imputer.fit_transform(X_train[categorical_cols])\n",
        "\n",
        "    return X_filled, time.time() - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TImo930RjFly"
      },
      "outputs": [],
      "source": [
        "def impute_knn(X_train, categorical_cols, numerical_cols):\n",
        "    \"\"\"KNN Imputation\"\"\"\n",
        "    start = time.time()\n",
        "    X_working = X_train.copy()\n",
        "\n",
        "    # ordinal encoding for categoricals\n",
        "    encoders = {}\n",
        "    for col in categorical_cols:\n",
        "        series = X_working[col].astype(str)\n",
        "        series[X_train[col].isna()] = np.nan\n",
        "\n",
        "        oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan, encoded_missing_value=np.nan)\n",
        "\n",
        "        X_working[[col]] = oe.fit_transform(X_working[[col]])\n",
        "        encoders[col] = oe\n",
        "\n",
        "    imputer = KNNImputer(n_neighbors=5)\n",
        "    X_filled = imputer.fit_transform(X_working)\n",
        "    X_filled = pd.DataFrame(X_filled, columns=X_working.columns, index=X_working.index)\n",
        "\n",
        "    # decode categoricals back\n",
        "    for col in categorical_cols:\n",
        "        oe = encoders[col]\n",
        "        X_filled[[col]] = oe.inverse_transform(X_filled[[col]])\n",
        "\n",
        "    return X_filled, time.time() - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDxTkp3njHab"
      },
      "outputs": [],
      "source": [
        "def impute_mice(X_train, categorical_cols, numerical_cols):\n",
        "    \"\"\"MICE Imputation (IterativeImputer)\"\"\"\n",
        "    start = time.time()\n",
        "    X_working = X_train.copy()\n",
        "\n",
        "    # ordinal encoding\n",
        "    encoders = {}\n",
        "    for col in categorical_cols:\n",
        "        # separate encoder for every column\n",
        "        oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan, encoded_missing_value=np.nan)\n",
        "        X_working[[col]] = oe.fit_transform(X_working[[col]])\n",
        "        encoders[col] = oe\n",
        "\n",
        "    imputer = IterativeImputer(max_iter=10, random_state=777)\n",
        "    X_filled = imputer.fit_transform(X_working)\n",
        "    X_filled = pd.DataFrame(X_filled, columns=X_working.columns, index=X_working.index)\n",
        "\n",
        "    # decoding back\n",
        "    for col in categorical_cols:\n",
        "        oe = encoders[col]\n",
        "        series = X_filled[col].round()\n",
        "\n",
        "        # clip the prediction to the acceptable range\n",
        "        n_categories = len(oe.categories_[0])\n",
        "        series = series.clip(0, n_categories - 1)\n",
        "\n",
        "        X_filled[col] = series\n",
        "        X_filled[[col]] = oe.inverse_transform(X_filled[[col]])\n",
        "\n",
        "    return X_filled, time.time() - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDXqWBHvjJWi"
      },
      "outputs": [],
      "source": [
        "def impute_sap_rpt(X_train, categorical_cols, numerical_cols):\n",
        "    \"\"\"SAP RPT Imputation\"\"\"\n",
        "    start = time.time()\n",
        "    X_imputed = X_train.copy()\n",
        "\n",
        "    missing_cols = X_train.columns[X_train.isna().any()].tolist()\n",
        "\n",
        "    for col in missing_cols:\n",
        "        # taking rows that have the needed data as context to predict the rows with missing data\n",
        "        mask_missing = X_imputed[col].isna()\n",
        "\n",
        "        X_context = X_imputed[~mask_missing].drop(columns=[col])\n",
        "        y_context = X_imputed.loc[~mask_missing, col]\n",
        "\n",
        "        X_target = X_imputed[mask_missing].drop(columns=[col])\n",
        "\n",
        "        if len(X_target) == 0:\n",
        "            continue\n",
        "\n",
        "        print(f\"  > RPT repairing column: {col} ({len(X_target)} missing)\")\n",
        "\n",
        "        if col in numerical_cols:\n",
        "            model = SAP_RPT_OSS_Regressor(max_context_size=1024)\n",
        "        else:\n",
        "            model = SAP_RPT_OSS_Classifier(max_context_size=1024)\n",
        "\n",
        "        model.fit(X_context, y_context)\n",
        "        preds = model.predict(X_target)\n",
        "        X_imputed.loc[mask_missing, col] = preds\n",
        "\n",
        "    return X_imputed, time.time() - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWGnp6t4jLHh"
      },
      "outputs": [],
      "source": [
        "def evaluate_reconstruction(X_clean, X_imputed, categorical_cols, numerical_cols):\n",
        "    X_cl = X_clean.loc[X_imputed.index]\n",
        "\n",
        "    # RMSE for numericals\n",
        "    if len(numerical_cols) > 0:\n",
        "        rmse = np.sqrt(mean_squared_error(X_cl[numerical_cols], X_imputed[numerical_cols]))\n",
        "    else:\n",
        "        rmse = 0.0\n",
        "\n",
        "    # accuracy for categoricals\n",
        "    if len(categorical_cols) > 0:\n",
        "        # flatten to compare all cells at once\n",
        "        acc = accuracy_score(\n",
        "            X_cl[categorical_cols].astype(str).values.flatten(),\n",
        "            X_imputed[categorical_cols].astype(str).values.flatten()\n",
        "        )\n",
        "    else:\n",
        "        acc = 0.0\n",
        "\n",
        "    return rmse, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD-XS84MjN0R"
      },
      "outputs": [],
      "source": [
        "def evaluate_downstream(X_train_imp, y_train, X_test_clean, y_test, cat_cols, num_cols):\n",
        "    transformers = [('num', StandardScaler(), num_cols)]\n",
        "    if cat_cols:\n",
        "        transformers.append(('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols))\n",
        "\n",
        "    preprocessor = ColumnTransformer(transformers)\n",
        "\n",
        "    target_type = type_of_target(y_train)\n",
        "    is_regression = target_type in ['continuous', 'continuous-multioutput']\n",
        "\n",
        "    if is_regression:\n",
        "        model = make_pipeline(preprocessor, RandomForestRegressor(n_estimators=50, max_depth=10, n_jobs=-1, random_state=777))\n",
        "    else:\n",
        "        model = make_pipeline(preprocessor, RandomForestClassifier(n_estimators=50, max_depth=10, n_jobs=-1, random_state=777))\n",
        "\n",
        "    model.fit(X_train_imp, y_train)\n",
        "    y_pred = model.predict(X_test_clean)\n",
        "\n",
        "    if is_regression:\n",
        "        return {\n",
        "            'R2': r2_score(y_test, y_pred),\n",
        "            'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "            'Type': 'Regression'\n",
        "        }\n",
        "    else:\n",
        "        y_pred_proba = model.predict_proba(X_test_clean)[:, 1]\n",
        "        return {\n",
        "            'AUC': roc_auc_score(y_test, y_pred_proba),\n",
        "            'F1': f1_score(y_test, y_pred),\n",
        "            'Type': 'Classification'\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_eBDXTUjPhI"
      },
      "outputs": [],
      "source": [
        "def run_benchmark(mechanism='MCAR', corruption_ratio=0.3):\n",
        "    X_train, X_test, y_train, y_test, cat_cols, num_cols = load_gas_turbine_data()\n",
        "    original_std = X_train[num_cols].std()\n",
        "\n",
        "    X_train_corrupt = corrupt_data(X_train, num_cols, mechanism=mechanism, ratio=corruption_ratio)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    methods = {\n",
        "        'Baseline (Mean/Mode)': impute_baseline,\n",
        "        'KNN': impute_knn,\n",
        "        'MICE': impute_mice,\n",
        "        'SAP_RPT': impute_sap_rpt\n",
        "    }\n",
        "\n",
        "    print(f\"\\n--- Starting Benchmark ({mechanism}) ---\")\n",
        "    for name, func in methods.items():\n",
        "        print(f\"Running {name}...\")\n",
        "\n",
        "        try:\n",
        "            X_imputed, time_taken = func(X_train_corrupt, cat_cols, num_cols)\n",
        "        except Exception as e:\n",
        "            print(f\"Method {name} failed: {e}\")\n",
        "            continue\n",
        "\n",
        "        rmse, acc = evaluate_reconstruction(X_train, X_imputed, cat_cols, num_cols)\n",
        "\n",
        "        imputed_std = X_imputed[num_cols].std()\n",
        "        std_recovery_ratio = (imputed_std / original_std).mean()\n",
        "\n",
        "        downstream = evaluate_downstream(X_imputed, y_train, X_test, y_test, cat_cols, num_cols)\n",
        "\n",
        "        res_row = {\n",
        "            'Method': name,\n",
        "            'Mechanism': mechanism,\n",
        "            'Time (s)': round(time_taken, 2),\n",
        "            'Rec_RMSE': round(rmse, 4),\n",
        "            'Std_Dev_Ratio': round(std_recovery_ratio, 4),\n",
        "            'Task_Type': downstream.get('Type', 'Unknown')\n",
        "        }\n",
        "\n",
        "        if downstream.get('Type') == 'Regression':\n",
        "            res_row['Downstream_R2'] = round(downstream.get('R2', 0), 4)\n",
        "            res_row['Downstream_RMSE'] = round(downstream.get('RMSE', 0), 4)\n",
        "            print(f\"    -> Done. Time: {res_row['Time (s)']}s | R2: {res_row['Downstream_R2']}\")\n",
        "        else:\n",
        "            res_row['Downstream_AUC'] = round(downstream.get('AUC', 0), 4)\n",
        "            res_row['Downstream_F1'] = round(downstream.get('F1', 0), 4)\n",
        "            print(f\"    -> Done. Time: {res_row['Time (s)']}s | AUC: {res_row['Downstream_AUC']}\")\n",
        "\n",
        "        results.append(res_row)\n",
        "\n",
        "    return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veB3qzP4jXF0",
        "outputId": "04f9a534-827a-462f-dabe-2ae0b45ca895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Gas Turbine dataset...\n",
            "Data Loaded: (36733, 12)\n",
            "  > Applying MNAR corruption (strength=0.7)...\n",
            "\n",
            "--- Starting Benchmark (MNAR) ---\n",
            "Running Baseline (Mean/Mode)...\n",
            "    -> Done. Time: 0.02s | R2: 0.7151\n",
            "Running KNN...\n",
            "    -> Done. Time: 95.71s | R2: 0.683\n",
            "Running MICE...\n",
            "    -> Done. Time: 0.74s | R2: 0.7334\n",
            "Running SAP_RPT...\n",
            "  > RPT repairing column: year (11463 missing)\n",
            "  > RPT repairing column: AT (11799 missing)\n",
            "  > RPT repairing column: AP (11862 missing)\n",
            "  > RPT repairing column: AH (11747 missing)\n",
            "  > RPT repairing column: AFDP (11850 missing)\n",
            "  > RPT repairing column: GTEP (11658 missing)\n",
            "  > RPT repairing column: TIT (11621 missing)\n",
            "  > RPT repairing column: TAT (11780 missing)\n",
            "  > RPT repairing column: TEY (11851 missing)\n",
            "  > RPT repairing column: CDP (11805 missing)\n",
            "  > RPT repairing column: NOX (11708 missing)\n",
            "    -> Done. Time: 201.66s | R2: 0.7237\n",
            "\n",
            "--- Final Results ---\n",
            "                 Method Mechanism  Time (s)  Rec_RMSE  Std_Dev_Ratio  \\\n",
            "0  Baseline (Mean/Mode)      MNAR      0.02    7.7175         0.6233   \n",
            "1                   KNN      MNAR     95.71    7.7332         0.7150   \n",
            "2                  MICE      MNAR      0.74    5.4459         0.8038   \n",
            "3               SAP_RPT      MNAR    201.66    4.3507         0.8793   \n",
            "\n",
            "    Task_Type  Downstream_R2  Downstream_RMSE  \n",
            "0  Regression         0.7151           1.2447  \n",
            "1  Regression         0.6830           1.3128  \n",
            "2  Regression         0.7334           1.2039  \n",
            "3  Regression         0.7237           1.2258  \n"
          ]
        }
      ],
      "source": [
        "df_results = run_benchmark(mechanism='MNAR', corruption_ratio=0.7)\n",
        "print(\"\\n--- Final Results ---\")\n",
        "print(df_results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
